{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391552e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy scipy h5py tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy scipy h5py tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d041aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_DIR = Path('/content/drive/MyDrive/algonauts_2023_tutorial_data')  # 公式チュートリアルのデータ配置先\n",
    "SUBJECT = 'subj01'  # subj01〜subj08\n",
    "USE_RELIABILITY_MASK = False  # 信頼度マスクを掛ける場合 True\n",
    "TIME_AGG = 'mean'  # 'mean' | 'median' | 'first' | 'last'\n",
    "SAMPLE_INDEX = 0  # 抽出サンプル index (test→val→train の優先順)\n",
    "\n",
    "ROOT = BASE_DIR / SUBJECT\n",
    "print('ROOT:', ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405fc99",
   "metadata": {},
   "source": [
    "## 1. パス解決 (左右別ファイル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84246ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_for(split: str, hemi: str):\n",
    "    # 例: training_split/training_fmri/lh_training_fmri.npy\n",
    "    candidates = [\n",
    "        ROOT / f'{split}_split' / f'{split}_fmri' / f'{hemi}_{split}_fmri.npy',\n",
    "        ROOT / f'{split}_fmri' / f'{hemi}_{split}_fmri.npy',\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "paths = {\n",
    "    'training_lh': path_for('training', 'lh'),\n",
    "    'training_rh': path_for('training', 'rh'),\n",
    "    'val_lh': path_for('val', 'lh'),\n",
    "    'val_rh': path_for('val', 'rh'),\n",
    "    'test_lh': path_for('test', 'lh'),\n",
    "    'test_rh': path_for('test', 'rh'),\n",
    "    'mask_lh': ROOT / 'reliability_masks' / 'lh_reliability_mask.npy',\n",
    "    'mask_rh': ROOT / 'reliability_masks' / 'rh_reliability_mask.npy',\n",
    "    'mask_all': ROOT / 'reliability_masks' / 'reliability_mask.npy',\n",
    "}\n",
    "for k, v in paths.items():\n",
    "    print(f\"{k}: {v if v and v.exists() else None}\")\n",
    "\n",
    "if not (paths['training_lh'] and paths['training_rh']):\n",
    "    raise FileNotFoundError('training の左右 fMRI が見つかりません。パスを確認してください。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71abc8e",
   "metadata": {},
   "source": [
    "## 2. ロード + 時間集約 + 左右結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21efa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_time(x: np.ndarray, mode: str):\n",
    "    if x.ndim == 2:  # (n, voxels)\n",
    "        return x\n",
    "    if x.ndim != 3:\n",
    "        raise ValueError(f'Unexpected ndim {x.ndim}, expected 2 or 3')\n",
    "    if mode == 'mean':\n",
    "        return x.mean(axis=1)\n",
    "    if mode == 'median':\n",
    "        return np.median(x, axis=1)\n",
    "    if mode == 'first':\n",
    "        return x[:, 0]\n",
    "    if mode == 'last':\n",
    "        return x[:, -1]\n",
    "    raise ValueError(f'Unknown TIME_AGG: {mode}')\n",
    "\n",
    "def load_split(split: str):\n",
    "    lh_path = paths[f'{split}_lh']\n",
    "    rh_path = paths[f'{split}_rh']\n",
    "    if lh_path is None or rh_path is None:\n",
    "        return None\n",
    "    lh = np.load(lh_path)\n",
    "    rh = np.load(rh_path)\n",
    "    lh = reduce_time(lh, TIME_AGG)\n",
    "    rh = reduce_time(rh, TIME_AGG)\n",
    "    if lh.shape[0] != rh.shape[0]:\n",
    "        raise ValueError(f'LH/RH sample count mismatch: {lh.shape} vs {rh.shape}')\n",
    "    return np.concatenate([lh, rh], axis=-1)\n",
    "\n",
    "train = load_split('training')\n",
    "val = load_split('val')\n",
    "test = load_split('test')\n",
    "print('train shape:', None if train is None else train.shape)\n",
    "print('val shape:', None if val is None else val.shape)\n",
    "print('test shape:', None if test is None else test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9bec8",
   "metadata": {},
   "source": [
    "## 3. 信頼度マスク (任意) 適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ad31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(arr, mask):\n",
    "    return arr[:, mask] if arr is not None else None\n",
    "\n",
    "if USE_RELIABILITY_MASK:\n",
    "    if paths['mask_all'].exists():\n",
    "        mask = np.load(paths['mask_all']).astype(bool)\n",
    "        train = apply_mask(train, mask)\n",
    "        val = apply_mask(val, mask)\n",
    "        test = apply_mask(test, mask)\n",
    "    else:\n",
    "        mask_l = np.load(paths['mask_lh']).astype(bool) if paths['mask_lh'].exists() else None\n",
    "        mask_r = np.load(paths['mask_rh']).astype(bool) if paths['mask_rh'].exists() else None\n",
    "        if mask_l is None or mask_r is None:\n",
    "            raise FileNotFoundError('信頼度マスクが見つかりません。USE_RELIABILITY_MASK=False にするかパスを確認してください。')\n",
    "        mask = np.concatenate([mask_l, mask_r])\n",
    "        train = apply_mask(train, mask)\n",
    "        val = apply_mask(val, mask)\n",
    "        test = apply_mask(test, mask)\n",
    "    print('mask applied, new shapes:', None if train is None else train.shape)\n",
    "else:\n",
    "    print('mask not applied')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a01d8b",
   "metadata": {},
   "source": [
    "## 4. z-score (train 統計) と無分散ボクセル除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train is None:\n",
    "    raise RuntimeError('train split が読み込めません。パス設定を確認してください。')\n",
    "mu = train.mean(axis=0, keepdims=True)\n",
    "sigma = train.std(axis=0, keepdims=True)\n",
    "nonzero = (sigma > 1e-8).ravel()\n",
    "train = train[:, nonzero]\n",
    "val = val[:, nonzero] if val is not None else None\n",
    "test = test[:, nonzero] if test is not None else None\n",
    "mu = mu[:, nonzero]\n",
    "sigma = sigma[:, nonzero]\n",
    "train_z = (train - mu) / sigma\n",
    "val_z = (val - mu) / sigma if val is not None else None\n",
    "test_z = (test - mu) / sigma if test is not None else None\n",
    "print('kept voxels:', train_z.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83e817",
   "metadata": {},
   "source": [
    "## 5. 1 サンプル抽出して voxel.npy 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33212351",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_arr = test_z if test_z is not None else val_z if val_z is not None else train_z\n",
    "if source_arr is None:\n",
    "    raise RuntimeError('抽出元がありません')\n",
    "SAMPLE_INDEX = min(SAMPLE_INDEX, source_arr.shape[0]-1)\n",
    "voxel_vec = source_arr[SAMPLE_INDEX].astype(np.float32)\n",
    "np.save('voxel.npy', voxel_vec)\n",
    "print('saved voxel.npy', voxel_vec.shape, voxel_vec.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1703e6",
   "metadata": {},
   "source": [
    "## 6. 簡易チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f124aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_z mean/std:', train_z.mean(), train_z.std())\n",
    "if test_z is not None: print('test_z mean/std:', test_z.mean(), test_z.std())\n",
    "if val_z is not None: print('val_z mean/std:', val_z.mean(), val_z.std())\n",
    "print('voxel head:', voxel_vec[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24084778",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy scipy h5py tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a090a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_DIR = Path('/content/drive/MyDrive/algonauts_2023_tutorial_data')  # 公式チュートリアルのデータ配置先\n",
    "SUBJECT = 'subj01'  # subj01〜subj08\n",
    "USE_RELIABILITY_MASK = False  # 信頼度マスクを掛ける場合 True\n",
    "TIME_AGG = 'mean'  # 'mean' | 'median' | 'first' | 'last'\n",
    "SAMPLE_INDEX = 0  # 抽出サンプル index (test→val→train の優先順)\n",
    "\n",
    "ROOT = BASE_DIR / SUBJECT\n",
    "print('ROOT:', ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25e95a",
   "metadata": {},
   "source": [
    "## 1. パス解決 (左右別ファイル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ea5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_for(split: str, hemi: str):\n",
    "    # 例: training_split/training_fmri/lh_training_fmri.npy\n",
    "    candidates = [\n",
    "        ROOT / f'{split}_split' / f'{split}_fmri' / f'{hemi}_{split}_fmri.npy',\n",
    "        ROOT / f'{split}_fmri' / f'{hemi}_{split}_fmri.npy',\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "paths = {\n",
    "    'train_lh': path_for('training', 'lh'),\n",
    "    'train_rh': path_for('training', 'rh'),\n",
    "    'val_lh': path_for('val', 'lh'),\n",
    "    'val_rh': path_for('val', 'rh'),\n",
    "    'test_lh': path_for('test', 'lh'),\n",
    "    'test_rh': path_for('test', 'rh'),\n",
    "    'mask_lh': ROOT / 'reliability_masks' / 'lh_reliability_mask.npy',\n",
    "    'mask_rh': ROOT / 'reliability_masks' / 'rh_reliability_mask.npy',\n",
    "    'mask_all': ROOT / 'reliability_masks' / 'reliability_mask.npy',\n",
    "}\n",
    "for k, v in paths.items():\n",
    "    print(f\"{k}: {v if v and v.exists() else None}\")\n",
    "\n",
    "if not (paths['train_lh'] and paths['train_rh']):\n",
    "    raise FileNotFoundError('training の左右 fMRI が見つかりません。パスを確認してください。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c04ec4",
   "metadata": {},
   "source": [
    "## 2. ロード + 時間集約 + 左右結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8269339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_time(x: np.ndarray, mode: str):\n",
    "    if x.ndim == 2:  # (n, voxels)\n",
    "        return x\n",
    "    if x.ndim != 3:\n",
    "        raise ValueError(f'Unexpected ndim {x.ndim}, expected 2 or 3')\n",
    "    if mode == 'mean':\n",
    "        return x.mean(axis=1)\n",
    "    if mode == 'median':\n",
    "        return np.median(x, axis=1)\n",
    "    if mode == 'first':\n",
    "        return x[:, 0]\n",
    "    if mode == 'last':\n",
    "        return x[:, -1]\n",
    "    raise ValueError(f'Unknown TIME_AGG: {mode}')\n",
    "\n",
    "def load_split(split: str):\n",
    "    lh_path = paths[f'{split}_lh']\n",
    "    rh_path = paths[f'{split}_rh']\n",
    "    if lh_path is None or rh_path is None:\n",
    "        return None\n",
    "    lh = np.load(lh_path)\n",
    "    rh = np.load(rh_path)\n",
    "    lh = reduce_time(lh, TIME_AGG)\n",
    "    rh = reduce_time(rh, TIME_AGG)\n",
    "    if lh.shape[0] != rh.shape[0]:\n",
    "        raise ValueError(f'LH/RH sample count mismatch: {lh.shape} vs {rh.shape}')\n",
    "    return np.concatenate([lh, rh], axis=-1)\n",
    "\n",
    "train = load_split('train') if 'train_lh' in paths else load_split('training')\n",
    "if train is None:\n",
    "    train = load_split('training')\n",
    "val = load_split('val')\n",
    "test = load_split('test')\n",
    "print('train shape:', None if train is None else train.shape)\n",
    "print('val shape:', None if val is None else val.shape)\n",
    "print('test shape:', None if test is None else test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe1d83",
   "metadata": {},
   "source": [
    "## 3. 信頼度マスク (任意) 適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(arr, mask):\n",
    "    return arr[:, mask] if arr is not None else None\n",
    "\n",
    "if USE_RELIABILITY_MASK:\n",
    "    if paths['mask_all'].exists():\n",
    "        mask = np.load(paths['mask_all']).astype(bool)\n",
    "        train = apply_mask(train, mask)\n",
    "        val = apply_mask(val, mask)\n",
    "        test = apply_mask(test, mask)\n",
    "    else:\n",
    "        mask_l = np.load(paths['mask_lh']).astype(bool) if paths['mask_lh'].exists() else None\n",
    "        mask_r = np.load(paths['mask_rh']).astype(bool) if paths['mask_rh'].exists() else None\n",
    "        if mask_l is None or mask_r is None:\n",
    "            raise FileNotFoundError('信頼度マスクが見つかりません。USE_RELIABILITY_MASK=False にするかパスを確認してください。')\n",
    "        mask = np.concatenate([mask_l, mask_r])\n",
    "        train = apply_mask(train, mask)\n",
    "        val = apply_mask(val, mask)\n",
    "        test = apply_mask(test, mask)\n",
    "    print('mask applied, new shapes:', None if train is None else train.shape)\n",
    "else:\n",
    "    print('mask not applied')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771564b",
   "metadata": {},
   "source": [
    "## 4. z-score (train 統計) と無分散ボクセル除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train is None:\n",
    "    raise RuntimeError('train split が読み込めません。パス設定を確認してください。')\n",
    "mu = train.mean(axis=0, keepdims=True)\n",
    "sigma = train.std(axis=0, keepdims=True)\n",
    "nonzero = (sigma > 1e-8).ravel()\n",
    "train = train[:, nonzero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66665b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_DIR = Path('/content/drive/MyDrive/algonauts_2023_tutorial_data')  # Colab Drive 上の公式チュートリアルデータ\n",
    "SUBJECT = 'subj01'  # subj01〜subj08\n",
    "USE_RELIABILITY_MASK = False  # 信頼度マスクを掛ける場合 True\n",
    "TIME_AGG = 'mean'  # 'mean' | 'median' | 'first' | 'last'\n",
    "SAMPLE_INDEX = 0  # 抽出サンプル index (test→val→train 優先)\n",
    "\n",
    "ROOT = BASE_DIR / SUBJECT\n",
    "print('ROOT:', ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c5bad",
   "metadata": {},
   "source": [
    "## 1. パス解決 (左右別ファイル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f95955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_for(split: str, hemi: str):\n",
    "    # 例: training_split/training_fmri/lh_training_fmri.npy\n",
    "    candidates = [\n",
    "        ROOT / f'{split}_split' / f'{split}_fmri' / f'{hemi}_{split}_fmri.npy',\n",
    "        ROOT / f'{split}_fmri' / f'{hemi}_{split}_fmri.npy',\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "paths = {\n",
    "    'train_lh': path_for('training', 'lh'),\n",
    "    'train_rh': path_for('training', 'rh'),\n",
    "    'val_lh': path_for('val', 'lh'),\n",
    "    'val_rh': path_for('val', 'rh'),\n",
    "    'test_lh': path_for('test', 'lh'),\n",
    "    'test_rh': path_for('test', 'rh'),\n",
    "    'mask_lh': ROOT / 'reliability_masks' / 'lh_reliability_mask.npy',\n",
    "    'mask_rh': ROOT / 'reliability_masks' / 'rh_reliability_mask.npy',\n",
    "    'mask_all': ROOT / 'reliability_masks' / 'reliability_mask.npy',\n",
    "}\n",
    "for k, v in paths.items():\n",
    "    print(f\n",
    "\n",
    "if not (paths['train_lh'] and paths['train_rh']):\n",
    "    raise FileNotFoundError('training の左右 fMRI が見つかりません。パスを確認してください。')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0e850",
   "metadata": {},
   "source": [
    "## 2. ロード + 時間集約 + 左右結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_time(x: np.ndarray, mode: str):\n",
    "    if x.ndim == 2:  # (n, voxels)\n",
    "        return x\n",
    "    if x.ndim != 3:\n",
    "        raise ValueError(f'Unexpected ndim {x.ndim}, expected 2 or 3')\n",
    "    if mode == 'mean':\n",
    "        return x.mean(axis=1)\n",
    "    if mode == 'median':\n",
    "        return np.median(x, axis=1)\n",
    "    if mode == 'first':\n",
    "        return x[:, 0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "30e04e0d",
      "metadata": {
        "id": "30e04e0d"
      },
      "source": [
        "## 1. Ë®≠ÂÆö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9f18df81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f18df81",
        "outputId": "d9856e11-1c3f-46ac-ff52-1a1f88a6c309",
        "vscode": {
          "languageId": "ini"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracting /content/drive/MyDrive/algonauts_2023_challenge_data/train_data/subj01.zip to /content/data/algonauts_2023_challenge_data/train_data/\n",
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Google Drive„Çí„Éû„Ç¶„É≥„ÉàÔºàÊó¢„Å´„Éû„Ç¶„É≥„ÉàÊ∏à„Åø„ÅÆÂ†¥Âêà„ÅØ„Çπ„Ç≠„ÉÉ„ÉóÔºâ\n",
        "\n",
        "# „Éû„Ç¶„É≥„Éà\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# zip„Éï„Ç°„Ç§„É´„ÅÆ„Éë„ÇπÔºà‰æãÔºöGoogle Drive‰∏ä„ÅÆ„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂÖàÔºâ\n",
        "zip_path = \"/content/drive/MyDrive/algonauts_2023_challenge_data/train_data/subj01.zip\"  # Â§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        "\n",
        "# Â±ïÈñãÂÖà„Éá„Ç£„É¨„ÇØ„Éà„É™\n",
        "extract_path = \"/content/data/algonauts_2023_challenge_data/train_data/\"  # Â§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        "\n",
        "# zip„Éï„Ç°„Ç§„É´„ÅÆÁ¢∫Ë™ç„Å®Â±ïÈñã\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"Extracting {zip_path} to {extract_path}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(f\"Zip file not found at: {zip_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1de1933e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1de1933e",
        "outputId": "f376733f-5873-4edb-8e4d-0188e90ce00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mode: dummy\n",
            "Hidden Dim: 256\n",
            "Batch Size: 2\n",
            "Epochs: 1\n",
            "Dummy Mode: True\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Â≠¶ÁøíË®≠ÂÆö - ÂøÖË¶Å„Å´Âøú„Åò„Å¶Â§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        "# =============================================================================\n",
        "\n",
        "# Â≠¶Áøí„É¢„Éº„Éâ: \"dummy\" | \"light\" | \"standard\"\n",
        "TRAIN_MODE = \"dummy\"\n",
        "\n",
        "# Ë¢´È®ìËÄÖID\n",
        "SUBJECT = \"subj01\"\n",
        "\n",
        "# „Éá„Éº„Çø„Éë„ÇπÔºàGoogle Drive‰∏äÔºâ\n",
        "DATA_ROOT = \"/content/data/algonauts_2023_challenge_data/train_data/\"\n",
        "\n",
        "# „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà‰øùÂ≠òÂÖà\n",
        "CHECKPOINT_DIR = \"/content/data/mindeye_checkpoints\"\n",
        "\n",
        "# Êó¢Â≠ò„ÅÆÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´ÔºàËª¢ÁßªÂ≠¶ÁøíÁî®„ÄÅNone„ÅÆÂ†¥Âêà„ÅØ„Çπ„Ç≠„ÉÉ„ÉóÔºâ\n",
        "PRETRAINED_CKPT = None  # ‰æã: \"/content/drive/MyDrive/train_logs/multisubject_subj01_1024hid_nolow_300ep\"\n",
        "\n",
        "# =============================================================================\n",
        "# „É¢„Éº„ÉâÂà•Ë®≠ÂÆöÔºàËá™ÂãïË®≠ÂÆöÔºâ\n",
        "# =============================================================================\n",
        "if TRAIN_MODE == \"dummy\":\n",
        "    HIDDEN_DIM = 256\n",
        "    BATCH_SIZE = 2\n",
        "    NUM_EPOCHS = 1\n",
        "    USE_PRIOR = False\n",
        "    BLURRY_RECON = False\n",
        "    DUMMY_MODE = True\n",
        "elif TRAIN_MODE == \"light\":\n",
        "    HIDDEN_DIM = 512\n",
        "    BATCH_SIZE = 4\n",
        "    NUM_EPOCHS = 10\n",
        "    USE_PRIOR = False\n",
        "    BLURRY_RECON = False\n",
        "    DUMMY_MODE = False\n",
        "else:  # standard\n",
        "    HIDDEN_DIM = 1024\n",
        "    BATCH_SIZE = 8\n",
        "    NUM_EPOCHS = 50\n",
        "    USE_PRIOR = True\n",
        "    BLURRY_RECON = False\n",
        "    DUMMY_MODE = False\n",
        "\n",
        "print(f\"Mode: {TRAIN_MODE}\")\n",
        "print(f\"Hidden Dim: {HIDDEN_DIM}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Dummy Mode: {DUMMY_MODE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f892613",
      "metadata": {
        "id": "9f892613"
      },
      "source": [
        "## 2. Áí∞Â¢ÉÊßãÁØâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fef90d8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fef90d8a",
        "outputId": "07539b64-de84-4e32-e606-fd942ca07579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jan 13 03:36:24 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# GPU„ÅÆÁ¢∫Ë™ç\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24a979c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24a979c8",
        "outputId": "df42c61f-2e73-4f93-e43f-d79380da228f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úì DUMMY_MODE: Skipping heavy libraries (dalle2-pytorch, kornia, pytorch_lightning)\n"
          ]
        }
      ],
      "source": [
        "# Âü∫Êú¨„Éë„ÉÉ„Ç±„Éº„Ç∏ÔºàÂ∏∏„Å´ÂøÖË¶ÅÔºâ\n",
        "!pip install -q torch torchvision tqdm einops h5py pillow matplotlib requests numpy\n",
        "!pip install -q omegaconf accelerate\n",
        "\n",
        "# OpenAI CLIPÔºàsrc/models.py„ÅåÂøÖË¶ÅÔºâ\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# webdatasetÔºàsrc/utils.py„ÅåÂøÖË¶ÅÔºâ\n",
        "!pip install -q webdataset\n",
        "\n",
        "# OpenCLIP\n",
        "!pip install -q open_clip_torch\n",
        "\n",
        "# ‚ö†Ô∏è DUMMY_MODE=True„ÅÆÂ†¥Âêà„ÅØÈáç„ÅÑ„É©„Ç§„Éñ„É©„É™„Çí„Çπ„Ç≠„ÉÉ„Éó\n",
        "if DUMMY_MODE:\n",
        "    print(\"‚úì DUMMY_MODE: Skipping heavy libraries (dalle2-pytorch, kornia, pytorch_lightning)\")\n",
        "else:\n",
        "    # Êú¨Áï™„É¢„Éº„ÉâÁî®„ÅÆÈáç„ÅÑ„Éë„ÉÉ„Ç±„Éº„Ç∏\n",
        "    !pip install -q pytorch_lightning\n",
        "    !pip install -q kornia\n",
        "    !pip install -q dalle2-pytorch\n",
        "    !pip install -q diffusers transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1062b8c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1062b8c4",
        "outputId": "6e739e11-1a4d-4120-e468-5d884de0c63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository already exists\n",
            "Working directory: /content/MindEyeV2\n"
          ]
        }
      ],
      "source": [
        "# „É™„Éù„Ç∏„Éà„É™„ÅÆ„ÇØ„É≠„Éº„É≥ÔºàÊó¢Â≠ò„ÅÆÂ†¥Âêà„ÅØ„Çπ„Ç≠„ÉÉ„ÉóÔºâ\n",
        "import os\n",
        "if not os.path.exists(\"/content/MindEyeV2\"):\n",
        "    # TODO: Ëá™ÂàÜ„ÅÆ„Éï„Ç©„Éº„ÇØ„Åó„Åü„É™„Éù„Ç∏„Éà„É™URL„Å´Â§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n",
        "    !git clone https://github.com/boxed-mikann/MindEyeV2.git /content/MindEyeV2\n",
        "else:\n",
        "    print(\"Repository already exists\")\n",
        "\n",
        "# „Éë„Çπ„ÇíËøΩÂä†\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/MindEyeV2/mysrc\")\n",
        "sys.path.insert(0, \"/content/MindEyeV2/src\")\n",
        "\n",
        "os.chdir(\"/content/MindEyeV2\")\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "StGS0JkILkyW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGS0JkILkyW",
        "outputId": "a707a38a-26fe-4719-b67a-c71ea12fc9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pulling latest changes from MindEyeV2 repository...\n",
            "Already up to date.\n",
            "Repository update complete.\n"
          ]
        }
      ],
      "source": [
        "print('Pulling latest changes from MindEyeV2 repository...')\n",
        "!git pull\n",
        "print('Repository update complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6985daca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6985daca",
        "outputId": "8d4288ca-a5ac-42b7-cdd0-173671013d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úì Data found: /content/data/algonauts_2023_challenge_data/train_data/subj01\n",
            "total 20\n",
            "drwxr-xr-x 5 root root 4096 Jan 13 02:13 .\n",
            "drwxr-xr-x 3 root root 4096 Jan 13 02:13 ..\n",
            "drwxr-xr-x 2 root root 4096 Jan 13 02:13 roi_masks\n",
            "drwxr-xr-x 3 root root 4096 Jan 13 02:13 test_split\n",
            "drwxr-xr-x 4 root root 4096 Jan 13 02:14 training_split\n"
          ]
        }
      ],
      "source": [
        "# Google Drive„Çí„Éû„Ç¶„É≥„Éà\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# „Éá„Éº„Çø„ÅÆÂ≠òÂú®Á¢∫Ë™ç\n",
        "import os\n",
        "subj_dir = os.path.join(DATA_ROOT, SUBJECT)\n",
        "if os.path.exists(subj_dir):\n",
        "    print(f\"‚úì Data found: {subj_dir}\")\n",
        "    !ls -la {subj_dir}\n",
        "else:\n",
        "    print(f\"‚úó Data NOT found: {subj_dir}\")\n",
        "    print(\"Please upload Algonauts2023 data to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf51bdb",
      "metadata": {
        "id": "2bf51bdb"
      },
      "source": [
        "## 3. „Éá„Éº„ÇøË™≠„ÅøËæº„Åø"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3f3bafa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f3bafa2",
        "outputId": "026509ff-274c-4047-9800-9e7ead94ffe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MindEyeV2 Algonauts Configuration\n",
            "============================================================\n",
            "Environment:     Colab\n",
            "Device:          cuda\n",
            "Dummy Mode:      True\n",
            "Data Root:       /content/drive/MyDrive/algonauts_2023_challenge_data\n",
            "Checkpoint Dir:  /content/drive/MyDrive/mindeye_checkpoints\n",
            "Output Dir:      /content/outputs\n",
            "SRC Dir:         /content/MindEyeV2/src\n",
            "============================================================\n",
            "\n",
            "Device: cuda\n",
            "Total vertices for subj01: 39548\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Áí∞Â¢ÉÂ§âÊï∞„Åß„ÉÄ„Éü„Éº„É¢„Éº„Éâ„ÇíË®≠ÂÆö\n",
        "os.environ[\"MINDEYE_DUMMY\"] = \"1\" if DUMMY_MODE else \"0\"\n",
        "\n",
        "# mysrc„É¢„Ç∏„É•„Éº„É´„Çí„Ç§„É≥„Éù„Éº„Éà\n",
        "from algonauts_dataset import AlgonautsDataset, get_dataloader, get_total_vertices\n",
        "from config import print_config, DEVICE\n",
        "\n",
        "print_config()\n",
        "print(f\"\\nDevice: {DEVICE}\")\n",
        "print(f\"Total vertices for {SUBJECT}: {get_total_vertices(SUBJECT)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0pp7KTZjWpDh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pp7KTZjWpDh",
        "outputId": "126e792e-9741-4044-8817-e492bcd8b470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìä Memory Usage BEFORE Model Creation\n",
            "============================================================\n",
            "  cpu_mb: 514.94 MB\n",
            "  gpu_allocated_mb: 0.00 MB\n",
            "  gpu_reserved_mb: 0.00 MB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# üîç „É°„É¢„É™„Éá„Éê„ÉÉ„Ç∞ - „É¢„Éá„É´‰ΩúÊàêÂâç\n",
        "# =============================================================================\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "def get_memory_info():\n",
        "    \"\"\"CPU/GPU„É°„É¢„É™ÊÉÖÂ†±„ÇíË°®Á§∫\"\"\"\n",
        "    # CPU„É°„É¢„É™\n",
        "    process = psutil.Process()\n",
        "    cpu_mem_mb = process.memory_info().rss / 1024**2\n",
        "\n",
        "    # GPU„É°„É¢„É™\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_mem_mb = torch.cuda.memory_allocated() / 1024**2\n",
        "        gpu_reserved_mb = torch.cuda.memory_reserved() / 1024**2\n",
        "        return {\n",
        "            \"cpu_mb\": cpu_mem_mb,\n",
        "            \"gpu_allocated_mb\": gpu_mem_mb,\n",
        "            \"gpu_reserved_mb\": gpu_reserved_mb,\n",
        "        }\n",
        "    return {\"cpu_mb\": cpu_mem_mb}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä Memory Usage BEFORE Model Creation\")\n",
        "print(\"=\"*60)\n",
        "mem_before = get_memory_info()\n",
        "for k, v in mem_before.items():\n",
        "    print(f\"  {k}: {v:.2f} MB\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "936f9ce3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936f9ce3",
        "outputId": "3e768d6e-66c0-4469-c7a5-b741162c2176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading fMRI data for subj01...\n",
            "  LH shape: (9841, 19004), RH shape: (9841, 20544)\n",
            "  Combined shape: (9841, 39548)\n",
            "Found 9841 train images\n",
            "\n",
            "Dataset size: 9841\n",
            "Number of batches: 4920\n",
            "\n",
            "Sample batch:\n",
            "  fMRI shape: torch.Size([2, 39548])\n",
            "  Image shape: torch.Size([2, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# „Éá„Éº„Çø„É≠„Éº„ÉÄ„Éº‰ΩúÊàê\n",
        "train_loader = get_dataloader(\n",
        "    data_root=DATA_ROOT,\n",
        "    subject=SUBJECT,\n",
        "    split=\"train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset size: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of batches: {len(train_loader)}\")\n",
        "\n",
        "# „Çµ„É≥„Éó„É´„Éê„ÉÉ„ÉÅ„ÇíÂèñÂæó\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nSample batch:\")\n",
        "print(f\"  fMRI shape: {sample_batch['fmri'].shape}\")\n",
        "print(f\"  Image shape: {sample_batch['image'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3882cc",
      "metadata": {
        "id": "6e3882cc"
      },
      "source": [
        "## 4. „É¢„Éá„É´‰ΩúÊàê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0f9d2104",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9d2104",
        "outputId": "4d608ab8-fdbf-4194-bc5f-f5a267537fde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:generative_models.sgm.modules.diffusionmodules.model:no module 'xformers'. Processing without...\n",
            "WARNING:generative_models.sgm.modules.attention:no module 'xformers'. Processing without...\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model created!\n",
            "============================================================\n",
            "Parameter Summary\n",
            "============================================================\n",
            "Total:      128,452,504\n",
            "Trainable:  128,452,504\n",
            "Frozen:               0\n",
            "------------------------------------------------------------\n",
            "By Layer:\n",
            "  üü¢ ridge                10,124,544 (10,124,544 trainable)\n",
            "  üü¢ backbone             118,327,960 (118,327,960 trainable)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from models_algonauts import AlgonautsMindEye, create_algonauts_model\n",
        "from transfer_utils import (\n",
        "    load_pretrained_without_ridge,\n",
        "    freeze_layers,\n",
        "    get_trainable_params,\n",
        "    print_parameter_summary,\n",
        ")\n",
        "\n",
        "# „É¢„Éá„É´‰ΩúÊàê\n",
        "model = create_algonauts_model(\n",
        "    subjects=[SUBJECT],\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    seq_len=1,\n",
        "    n_blocks=4,\n",
        "    use_prior=USE_PRIOR,\n",
        "    blurry_recon=BLURRY_RECON,\n",
        "    device=DEVICE,\n",
        ")\n",
        "\n",
        "print(\"Model created!\")\n",
        "print_parameter_summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cb1f86db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1f86db",
        "outputId": "78153e41-a0f7-4182-8e84-8eb0075839b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No pretrained checkpoint specified. Training from scratch.\n"
          ]
        }
      ],
      "source": [
        "# Ëª¢ÁßªÂ≠¶ÁøíÔºàÊó¢Â≠òckpt„Åå„ÅÇ„ÇãÂ†¥ÂêàÔºâ\n",
        "if PRETRAINED_CKPT and os.path.exists(PRETRAINED_CKPT):\n",
        "    print(f\"Loading pretrained weights from: {PRETRAINED_CKPT}\")\n",
        "    loaded, missing = load_pretrained_without_ridge(\n",
        "        model,\n",
        "        PRETRAINED_CKPT,\n",
        "        freeze_backbone=True,\n",
        "        freeze_prior=True,\n",
        "    )\n",
        "    print(f\"\\nAfter transfer learning:\")\n",
        "    print_parameter_summary(model)\n",
        "else:\n",
        "    print(\"No pretrained checkpoint specified. Training from scratch.\")\n",
        "    # „Çπ„ÇØ„É©„ÉÉ„ÉÅÂ≠¶Áøí„ÅÆÂ†¥Âêà„ÅØbackbone„ÇÇfreeze„Åó„Å™„ÅÑ\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3liT9FTmWvmm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3liT9FTmWvmm",
        "outputId": "8cf66267-5178-474a-fa51-d5533e57a4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìä Memory Usage AFTER Model Creation\n",
            "============================================================\n",
            "  cpu_mb: 4652.56 MB\n",
            "  gpu_allocated_mb: 490.02 MB\n",
            "  gpu_reserved_mb: 504.00 MB\n",
            "\n",
            "üìà Memory Increase:\n",
            "  cpu_mb: +4137.39 MB\n",
            "  gpu_allocated_mb: +490.02 MB\n",
            "  gpu_reserved_mb: +504.00 MB\n",
            "\n",
            "üßÆ Theoretical Model Size:\n",
            "  Total params: 128,452,504\n",
            "  Trainable params: 128,452,504\n",
            "  FP32 size: 490.01 MB\n",
            "  FP16 size: 245.00 MB\n",
            "\n",
            "üéØ Model Device: cuda:0\n",
            "   Data Type: torch.float32\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# üîç „É°„É¢„É™„Éá„Éê„ÉÉ„Ç∞ - „É¢„Éá„É´‰ΩúÊàêÂæå\n",
        "# =============================================================================\n",
        "print(\"=\"*60)\n",
        "print(\"üìä Memory Usage AFTER Model Creation\")\n",
        "print(\"=\"*60)\n",
        "mem_after = get_memory_info()\n",
        "for k, v in mem_after.items():\n",
        "    print(f\"  {k}: {v:.2f} MB\")\n",
        "\n",
        "print(\"\\nüìà Memory Increase:\")\n",
        "for k in mem_after.keys():\n",
        "    increase = mem_after[k] - mem_before.get(k, 0)\n",
        "    print(f\"  {k}: +{increase:.2f} MB\")\n",
        "\n",
        "# „É¢„Éá„É´„Éë„É©„É°„Éº„ÇøÊï∞\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# ÁêÜË´ñÁöÑ„Å™„É°„É¢„É™‰ΩøÁî®ÈáèÔºàFP32ÊÉ≥ÂÆöÔºâ\n",
        "theoretical_mb = total_params * 4 / 1024**2\n",
        "print(f\"\\nüßÆ Theoretical Model Size:\")\n",
        "print(f\"  Total params: {total_params:,}\")\n",
        "print(f\"  Trainable params: {trainable_params:,}\")\n",
        "print(f\"  FP32 size: {theoretical_mb:.2f} MB\")\n",
        "print(f\"  FP16 size: {theoretical_mb/2:.2f} MB\")\n",
        "\n",
        "# „É¢„Éá„É´„ÅåÂÆüÈöõ„Å´GPU‰∏ä„Å´„ÅÇ„Çã„ÅãÁ¢∫Ë™ç\n",
        "if torch.cuda.is_available():\n",
        "    sample_param = next(model.parameters())\n",
        "    print(f\"\\nüéØ Model Device: {sample_param.device}\")\n",
        "    print(f\"   Data Type: {sample_param.dtype}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3d8f04",
      "metadata": {
        "id": "7b3d8f04"
      },
      "source": [
        "## 5. CLIPÁâπÂæ¥„ÅÆÊ∫ñÂÇô"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "nAEaVivHYaP-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "nAEaVivHYaP-",
        "outputId": "fef4dd00-43bc-4985-87c2-9dc6ed1eb89c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìä DummyCLIPImageEmbedder Memory Check\n",
            "============================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'clip_embedder' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-556445613.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# „Éë„É©„É°„Éº„ÇøÊï∞\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclip_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclip_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mclip_size_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_params\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;31m# FP32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clip_embedder' is not defined"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# üîç CLIP Embedder „É°„É¢„É™„ÉÅ„Çß„ÉÉ„ÇØ\n",
        "# =============================================================================\n",
        "if DUMMY_MODE:\n",
        "    print(\"=\"*60)\n",
        "    print(\"üìä DummyCLIPImageEmbedder Memory Check\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # „Éë„É©„É°„Éº„ÇøÊï∞\n",
        "    clip_params = sum(p.numel() for p in clip_embedder.parameters())\n",
        "    clip_size_mb = clip_params * 4 / 1024**2  # FP32\n",
        "\n",
        "    print(f\"  Total params: {clip_params:,}\")\n",
        "    print(f\"  Theoretical size (FP32): {clip_size_mb:.2f} MB\")\n",
        "\n",
        "    # „Éá„Éê„Ç§„ÇπÁ¢∫Ë™ç\n",
        "    sample_param = next(clip_embedder.parameters())\n",
        "    print(f\"  Device: {sample_param.device}\")\n",
        "    print(f\"  Dtype: {sample_param.dtype}\")\n",
        "\n",
        "    # „É°„É¢„É™‰ΩøÁî®Èáè\n",
        "    mem_info = get_memory_info()\n",
        "    print(f\"\\n  Current CPU RAM: {mem_info['cpu_mb']:.2f} MB\")\n",
        "    if 'gpu_allocated_mb' in mem_info:\n",
        "        print(f\"  Current GPU RAM: {mem_info['gpu_allocated_mb']:.2f} MB\")\n",
        "\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f0b0f201",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "bc9b5a8cbd3a4119941e9e7b93455500",
            "56d8754cfee447a8a4bbe1c95a6e4ee1",
            "6e5ec983c10741ee87e5fefd371cc748",
            "7996b0610b624a289add344d00a72d9f",
            "650bdbc5a5d744039bf6f7c9aedf59c6",
            "24507560358f462cb8021f8f4ecb42ba",
            "ca7a99b3f5fa4c17b1edadd0f0321314",
            "1369be7e088f48c38298e34d674dd052",
            "2d3f8231f66a4d83b53e90ff2c6a9363",
            "2067b4ce007648cd93ebfa662e873155",
            "37947142af5443ef9a8c764cb956e90c"
          ]
        },
        "id": "f0b0f201",
        "outputId": "4acad06e-62f4-4054-e859-6d159aa77a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading OpenCLIP ViT-B-32 (lightweight version for Colab)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc9b5a8cbd3a4119941e9e7b93455500",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenCLIP loaded! Model on device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# „ÉÄ„Éü„Éº„É¢„Éº„Éâ„ÅÆÂ†¥Âêà„ÅØ„ÉÄ„Éü„ÉºCLIP„Çí‰ΩøÁî®\n",
        "if DUMMY_MODE:\n",
        "    from dummy_models import DummyCLIPImageEmbedder\n",
        "\n",
        "    clip_embedder = DummyCLIPImageEmbedder().to(DEVICE)\n",
        "    print(\"Using DummyCLIPImageEmbedder (ËªΩÈáè„ÉÄ„Éü„Éº„É¢„Éá„É´)\")\n",
        "\n",
        "else:\n",
        "    # Êú¨Áâ©„ÅÆCLIP„Çí‰ΩøÁî®ÔºàËªΩÈáèÁâàÔºâ\n",
        "    # ViT-bigG-14„ÅØ5GB‰ª•‰∏ä„ÅßColabÁÑ°ÊñôÁâà„Åß„ÅØ‰Ωø„Åà„Å™„ÅÑ„Åü„ÇÅ„ÄÅËªΩÈáèÁâà„Çí‰ΩøÁî®\n",
        "    try:\n",
        "        import open_clip\n",
        "\n",
        "        # ËªΩÈáèÁâàCLIPÔºàViT-B/32: Á¥Ñ350MBÔºâ\n",
        "        print(\"Loading OpenCLIP ViT-B-32 (lightweight version for Colab)...\")\n",
        "        clip_model, _, preprocess = open_clip.create_model_and_transforms(\n",
        "            \"ViT-B-32\",  # bigG-14„ÅÆ‰ª£„Çè„Çä„Å´ËªΩÈáèÁâà„Çí‰ΩøÁî®\n",
        "            pretrained=\"laion2b_s34b_b79k\",\n",
        "        )\n",
        "        clip_model = clip_model.to(DEVICE).eval()\n",
        "\n",
        "        for param in clip_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        print(f\"OpenCLIP loaded! Model on device: {next(clip_model.parameters()).device}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load OpenCLIP: {e}\")\n",
        "        print(\"Falling back to dummy mode\")\n",
        "        DUMMY_MODE = True\n",
        "        from dummy_models import DummyCLIPImageEmbedder\n",
        "        clip_embedder = DummyCLIPImageEmbedder().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "412dc816",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "412dc816",
        "outputId": "f3460962-0ab6-419f-b759-a4af4063dfea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLIP features shape: torch.Size([2, 512])\n"
          ]
        }
      ],
      "source": [
        "def get_clip_features(images):\n",
        "    \"\"\"ÁîªÂÉè„Åã„ÇâCLIPÁâπÂæ¥„ÇíÊäΩÂá∫\"\"\"\n",
        "    with torch.no_grad():\n",
        "        if DUMMY_MODE:\n",
        "            return clip_embedder(images)\n",
        "        else:\n",
        "            # OpenCLIP„Çí‰ΩøÁî®\n",
        "            features = clip_model.encode_image(images)\n",
        "            return features\n",
        "\n",
        "# „ÉÜ„Çπ„Éà\n",
        "test_images = sample_batch['image'].to(DEVICE)\n",
        "test_features = get_clip_features(test_images)\n",
        "print(f\"CLIP features shape: {test_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e701814",
      "metadata": {
        "id": "8e701814"
      },
      "source": [
        "## 6. Â≠¶Áøí„É´„Éº„Éó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a6d53128",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6d53128",
        "outputId": "2e716f83-9cc4-43b8-e99b-bc321b559e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters: 128,452,504\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "# „Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂ÔºàÂ≠¶ÁøíÂèØËÉΩ„Å™„Éë„É©„É°„Éº„Çø„ÅÆ„ÅøÔºâ\n",
        "trainable_params = get_trainable_params(model, mode=\"all_unfrozen\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in trainable_params):,}\")\n",
        "\n",
        "optimizer = AdamW(trainable_params, lr=3e-4, weight_decay=1e-2)\n",
        "\n",
        "# „Çπ„Ç±„Ç∏„É•„Éº„É©\n",
        "total_steps = len(train_loader) * NUM_EPOCHS\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=3e-4,\n",
        "    total_steps=total_steps,\n",
        "    pct_start=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0d06b396",
      "metadata": {
        "id": "0d06b396"
      },
      "outputs": [],
      "source": [
        "def soft_clip_loss(preds, targets, temp=0.006):\n",
        "    \"\"\"Soft CLIP contrastive loss\"\"\"\n",
        "    # Flatten to (batch, dim)\n",
        "    preds = preds.view(preds.shape[0], -1)\n",
        "    targets = targets.view(targets.shape[0], -1)\n",
        "\n",
        "    # Normalize\n",
        "    preds = F.normalize(preds, dim=-1)\n",
        "    targets = F.normalize(targets, dim=-1)\n",
        "\n",
        "    # Cosine similarity\n",
        "    logits = (preds @ targets.T) / temp\n",
        "    labels = torch.arange(len(logits), device=logits.device)\n",
        "\n",
        "    loss_i = F.cross_entropy(logits, labels)\n",
        "    loss_t = F.cross_entropy(logits.T, labels)\n",
        "\n",
        "    return (loss_i + loss_t) / 2\n",
        "\n",
        "def train_step(batch):\n",
        "    \"\"\"1„Éê„ÉÉ„ÉÅ„ÅÆÂ≠¶Áøí„Çπ„ÉÜ„ÉÉ„Éó\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    # „Éá„Éº„ÇøÂèñÂæó\n",
        "    fmri = batch['fmri'].to(DEVICE)\n",
        "    images = batch['image'].to(DEVICE)\n",
        "\n",
        "    # CLIPÁâπÂæ¥„ÇíÂèñÂæóÔºà„Çø„Éº„Ç≤„ÉÉ„ÉàÔºâ\n",
        "    with torch.no_grad():\n",
        "        clip_target = get_clip_features(images)\n",
        "\n",
        "    # Forward\n",
        "    backbone, clip_voxels, blurry = model(fmri)\n",
        "\n",
        "    # LossË®àÁÆó\n",
        "    # clip_voxels: (batch, seq, emb_dim)\n",
        "    # clip_target: (batch, seq, emb_dim) or (batch, emb_dim)\n",
        "    if clip_target.dim() == 2:\n",
        "        clip_target = clip_target.unsqueeze(1)\n",
        "\n",
        "    loss = soft_clip_loss(clip_voxels, clip_target)\n",
        "\n",
        "    # Backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(trainable_params, 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0d188f2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d188f2f",
        "outputId": "52fa9357-6fd9-4259-da49-5b7ccb10e196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory: 1.06 GB allocated\n",
            "GPU Memory: 1.10 GB reserved\n"
          ]
        }
      ],
      "source": [
        "# „É°„É¢„É™Á¢∫Ë™ç\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB allocated\")\n",
        "    print(f\"GPU Memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB reserved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "51e0367f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "d0dfe203d23041b9aeede9f0e54bd3e7",
            "69e934c6520a4fd0a724de7df1039aa6",
            "eb163e2004d8414c93af1e6961ce037a",
            "cd7340b752ea407cbc71ff3c8c05c0f2",
            "394d268177c7432db1d1f2c98b2990d8",
            "285ba4c598834b5b8b35babe0cfa09ce",
            "18fca8fde273464bbebfa68a15c12147",
            "42814c33b28d4295a0658c9985f5eb88",
            "9dea039f804742099391c34f85938ec6",
            "ebb8a67534a84a0cb2a244dde0e787fb",
            "e12e2de99cc44400a2728ef893ddef6d"
          ]
        },
        "id": "51e0367f",
        "outputId": "57cb5dbf-3154-4867-992a-9f0acb0f7d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Starting training: 1 epochs, 4920 batches/epoch\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0dfe203d23041b9aeede9f0e54bd3e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/1:   0%|          | 0/4920 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (2x425984 and 512x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2470480545.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{NUM_EPOCHS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mepoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{loss:.4f}\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-639488239.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mclip_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_clip_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_voxels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-639488239.py\u001b[0m in \u001b[0;36msoft_clip_loss\u001b[0;34m(preds, targets, temp)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Cosine similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x425984 and 512x2)"
          ]
        }
      ],
      "source": [
        "# Â≠¶Áøí„É´„Éº„Éó\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Starting training: {NUM_EPOCHS} epochs, {len(train_loader)} batches/epoch\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_losses = []\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for batch in pbar:\n",
        "        loss = train_step(batch)\n",
        "        epoch_losses.append(loss)\n",
        "        pbar.set_postfix({\"loss\": f\"{loss:.4f}\"})\n",
        "\n",
        "    avg_loss = np.mean(epoch_losses)\n",
        "    losses.extend(epoch_losses)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # „É°„É¢„É™Á¢∫Ë™ç\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Training complete!\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1cf52af",
      "metadata": {
        "id": "f1cf52af"
      },
      "outputs": [],
      "source": [
        "# ÊêçÂ§±„ÅÆÂèØË¶ñÂåñ\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f70e4d2f",
      "metadata": {
        "id": "f70e4d2f"
      },
      "source": [
        "## 7. „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà‰øùÂ≠ò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b93a67",
      "metadata": {
        "id": "39b93a67"
      },
      "outputs": [],
      "source": [
        "from transfer_utils import save_checkpoint\n",
        "\n",
        "# ‰øùÂ≠òÂÖà„Éá„Ç£„É¨„ÇØ„Éà„É™‰ΩúÊàê\n",
        "save_dir = os.path.join(CHECKPOINT_DIR, f\"algonauts_{SUBJECT}_{TRAIN_MODE}\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà‰øùÂ≠ò\n",
        "save_checkpoint(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    epoch=NUM_EPOCHS,\n",
        "    save_path=os.path.join(save_dir, \"last.pth\"),\n",
        "    extra_info={\n",
        "        \"train_mode\": TRAIN_MODE,\n",
        "        \"subject\": SUBJECT,\n",
        "        \"hidden_dim\": HIDDEN_DIM,\n",
        "        \"final_loss\": losses[-1] if losses else None,\n",
        "    },\n",
        ")\n",
        "\n",
        "print(f\"\\nCheckpoint saved to: {save_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c46259",
      "metadata": {
        "id": "d2c46259"
      },
      "source": [
        "## 8. Á∞°ÊòìÊ§úË®º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38dee4e2",
      "metadata": {
        "id": "38dee4e2"
      },
      "outputs": [],
      "source": [
        "# Êé®Ë´ñ„ÉÜ„Çπ„Éà\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_batch = next(iter(train_loader))\n",
        "    test_fmri = test_batch['fmri'].to(DEVICE)\n",
        "    test_images = test_batch['image'].to(DEVICE)\n",
        "\n",
        "    # fMRI ‚Üí CLIP tokens\n",
        "    backbone, clip_voxels, blurry = model(test_fmri)\n",
        "\n",
        "    # ÂÆüÈöõ„ÅÆCLIPÁâπÂæ¥\n",
        "    clip_target = get_clip_features(test_images)\n",
        "    if clip_target.dim() == 2:\n",
        "        clip_target = clip_target.unsqueeze(1)\n",
        "\n",
        "    # „Ç≥„Çµ„Ç§„É≥È°û‰ººÂ∫¶\n",
        "    pred_flat = F.normalize(clip_voxels.view(clip_voxels.shape[0], -1), dim=-1)\n",
        "    target_flat = F.normalize(clip_target.view(clip_target.shape[0], -1), dim=-1)\n",
        "\n",
        "    similarity = (pred_flat * target_flat).sum(dim=-1).mean()\n",
        "\n",
        "    print(f\"\\nInference test:\")\n",
        "    print(f\"  Input fMRI shape: {test_fmri.shape}\")\n",
        "    print(f\"  Output CLIP shape: {clip_voxels.shape}\")\n",
        "    print(f\"  Average cosine similarity: {similarity.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d962d6be",
      "metadata": {
        "id": "d962d6be"
      },
      "outputs": [],
      "source": [
        "# ÂÖ•ÂäõÁîªÂÉè„ÅÆÂèØË¶ñÂåñ\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def denormalize(tensor):\n",
        "    \"\"\"ImageNetÊ≠£Ë¶èÂåñ„ÇíÂÖÉ„Å´Êàª„Åô\"\"\"\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(tensor.device)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(tensor.device)\n",
        "    return tensor * std + mean\n",
        "\n",
        "# „Çµ„É≥„Éó„É´ÁîªÂÉè„ÇíË°®Á§∫\n",
        "sample_images = denormalize(test_images[:4])\n",
        "grid = make_grid(sample_images, nrow=4).cpu().permute(1, 2, 0).numpy()\n",
        "grid = np.clip(grid, 0, 1)\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.imshow(grid)\n",
        "plt.title(\"Sample Training Images\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d5bbd3",
      "metadata": {
        "id": "f9d5bbd3"
      },
      "source": [
        "## Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó\n",
        "\n",
        "1. **„ÉÄ„Éü„Éº„É¢„Éº„Éâ„ÅßÂãï‰ΩúÁ¢∫Ë™ç** ‚Üí „Ç®„É©„Éº„Å™„ÅèÂÆå‰∫Ü„Åô„Çå„Å∞OK\n",
        "2. **ËªΩÈáè„É¢„Éº„ÉâÔºàlightÔºâ„ÅßÂÆüÂ≠¶Áøí** ‚Üí T4„ÅßÊï∞ÊôÇÈñì\n",
        "3. **Ê®ôÊ∫ñ„É¢„Éº„ÉâÔºàstandardÔºâ„ÅßÊú¨Ê†ºÂ≠¶Áøí** ‚Üí Pro or Á†îÁ©∂ÂÆ§PC\n",
        "4. **Êé®Ë´ñ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ** ‚Üí `mindeye_inference_colab.ipynb` „ÅßÁîªÂÉèÂÜçÊßãÊàê"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1369be7e088f48c38298e34d674dd052": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fca8fde273464bbebfa68a15c12147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2067b4ce007648cd93ebfa662e873155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24507560358f462cb8021f8f4ecb42ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285ba4c598834b5b8b35babe0cfa09ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3f8231f66a4d83b53e90ff2c6a9363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37947142af5443ef9a8c764cb956e90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "394d268177c7432db1d1f2c98b2990d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42814c33b28d4295a0658c9985f5eb88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56d8754cfee447a8a4bbe1c95a6e4ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24507560358f462cb8021f8f4ecb42ba",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ca7a99b3f5fa4c17b1edadd0f0321314",
            "value": "open_clip_model.safetensors:‚Äá100%"
          }
        },
        "650bdbc5a5d744039bf6f7c9aedf59c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e934c6520a4fd0a724de7df1039aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_285ba4c598834b5b8b35babe0cfa09ce",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_18fca8fde273464bbebfa68a15c12147",
            "value": "Epoch‚Äá1/1:‚Äá‚Äá‚Äá0%"
          }
        },
        "6e5ec983c10741ee87e5fefd371cc748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1369be7e088f48c38298e34d674dd052",
            "max": 605143316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d3f8231f66a4d83b53e90ff2c6a9363",
            "value": 605143316
          }
        },
        "7996b0610b624a289add344d00a72d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2067b4ce007648cd93ebfa662e873155",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_37947142af5443ef9a8c764cb956e90c",
            "value": "‚Äá605M/605M‚Äá[00:06&lt;00:00,‚Äá178MB/s]"
          }
        },
        "9dea039f804742099391c34f85938ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc9b5a8cbd3a4119941e9e7b93455500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56d8754cfee447a8a4bbe1c95a6e4ee1",
              "IPY_MODEL_6e5ec983c10741ee87e5fefd371cc748",
              "IPY_MODEL_7996b0610b624a289add344d00a72d9f"
            ],
            "layout": "IPY_MODEL_650bdbc5a5d744039bf6f7c9aedf59c6"
          }
        },
        "ca7a99b3f5fa4c17b1edadd0f0321314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd7340b752ea407cbc71ff3c8c05c0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb8a67534a84a0cb2a244dde0e787fb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e12e2de99cc44400a2728ef893ddef6d",
            "value": "‚Äá0/4920‚Äá[00:01&lt;?,‚Äá?it/s]"
          }
        },
        "d0dfe203d23041b9aeede9f0e54bd3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69e934c6520a4fd0a724de7df1039aa6",
              "IPY_MODEL_eb163e2004d8414c93af1e6961ce037a",
              "IPY_MODEL_cd7340b752ea407cbc71ff3c8c05c0f2"
            ],
            "layout": "IPY_MODEL_394d268177c7432db1d1f2c98b2990d8"
          }
        },
        "e12e2de99cc44400a2728ef893ddef6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb163e2004d8414c93af1e6961ce037a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42814c33b28d4295a0658c9985f5eb88",
            "max": 4920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dea039f804742099391c34f85938ec6",
            "value": 0
          }
        },
        "ebb8a67534a84a0cb2a244dde0e787fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
